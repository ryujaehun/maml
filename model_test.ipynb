{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "from maml.metalearners import ModelAgnosticMetaLearning\n",
    "from torch.utils.data import  DataLoader\n",
    "from maml.datasets import get_benchmark_by_name\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Conv2dDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.__save_path='/home/jaehun/workspace/pytorch-maml/GCN'\n",
    "        self.__cost_path = os.path.join(self.__save_path,'conv2d','new_label.npy')\n",
    "        self.__feature_path = os.path.join(self.__save_path,'conv2d','new_batch_1.npy')\n",
    "        self.__costs=np.load(self.__cost_path).squeeze()\n",
    "#         self.__costs=self.__costs[:,1:]\n",
    "        self.__features=np.load(self.__feature_path).squeeze()\n",
    "    def __len__(self):\n",
    "        return len(self.__costs)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.__features[idx],self.__costs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths=glob.glob('results/graph_flops_order/**/config.json',recursive=True)\n",
    "conv2d_dataset=Conv2dDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 before loss adapt\n",
      " 0.12874145805835724\n",
      "before\toutput\n",
      " tensor([0.3424, 0.1257, 0.3793, 0.3424, 0.1481, 0.2744, 0.2354, 0.2190, 0.1205,\n",
      "        0.3687, 0.3222, 0.1802, 0.2542, 0.2995, 0.3538, 0.2098, 0.1765, 0.3488,\n",
      "        0.3371, 0.3190], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.1376, 0.1390, 0.1392, 0.1405, 0.1414, 0.1417, 0.1419, 0.1421, 0.1422,\n",
      "        0.1434, 0.1436, 0.1438, 0.1441, 0.1445, 0.1448, 0.1458, 0.1460, 0.1468,\n",
      "        0.1471, 0.1471], device='cuda:0')\n",
      "\n",
      "0 after loss adapt\n",
      " 0.08354370296001434\n",
      "after\toutput\n",
      " tensor([0.2383, 0.2479, 0.1808, 0.2831, 0.2553, 0.2319, 0.0738, 0.0412, 0.0677,\n",
      "        0.1847, 0.1816, 0.2358, 0.1852, 0.0696, 0.2286, 0.2732, 0.2643, 0.1269,\n",
      "        0.3068, 0.2532], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.1472, 0.1476, 0.1478, 0.1479, 0.1482, 0.1483, 0.1486, 0.1488, 0.1493,\n",
      "        0.1493, 0.1495, 0.1497, 0.1498, 0.1501, 0.1514, 0.1520, 0.1528, 0.1538,\n",
      "        0.1544, 0.1548], device='cuda:0')\n",
      "\n",
      "100 before loss adapt\n",
      " 0.45715877413749695\n",
      "before\toutput\n",
      " tensor([0.4028, 0.4423, 0.4881, 0.3646, 0.3171, 0.3840, 0.3392, 0.3773, 0.4551,\n",
      "        0.4391, 0.4869, 0.3015, 0.3894, 0.4756, 0.2826, 0.4470, 0.4880, 0.4498,\n",
      "        0.3073, 0.2637], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.8511, 0.8511, 0.8515, 0.8515, 0.8516, 0.8517, 0.8519, 0.8520, 0.8522,\n",
      "        0.8522, 0.8523, 0.8523, 0.8524, 0.8526, 0.8528, 0.8529, 0.8530, 0.8531,\n",
      "        0.8532, 0.8532], device='cuda:0')\n",
      "\n",
      "100 after loss adapt\n",
      " 0.20525076985359192\n",
      "after\toutput\n",
      " tensor([0.6961, 0.7709, 0.4815, 0.4671, 0.6091, 0.5470, 0.6199, 0.7256, 0.7135,\n",
      "        0.6367, 0.7111, 0.6812, 0.5520, 0.7976, 0.7901, 0.4622, 0.5839, 0.7908,\n",
      "        0.6705, 0.6779], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.8532, 0.8534, 0.8534, 0.8536, 0.8538, 0.8539, 0.8542, 0.8543, 0.8543,\n",
      "        0.8545, 0.8545, 0.8545, 0.8546, 0.8548, 0.8549, 0.8551, 0.8555, 0.8555,\n",
      "        0.8558, 0.8558], device='cuda:0')\n",
      "\n",
      "0 before loss adapt\n",
      " 0.026180783286690712\n",
      "before\toutput\n",
      " tensor([0.1173, 0.1875, 0.1347, 0.1173, 0.1660, 0.1070, 0.1377, 0.2058, 0.2408,\n",
      "        0.1257, 0.1542, 0.1426, 0.1121, 0.1556, 0.1461, 0.1151, 0.1137, 0.1194,\n",
      "        0.1764, 0.1427], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.1376, 0.1390, 0.1392, 0.1405, 0.1414, 0.1417, 0.1419, 0.1421, 0.1422,\n",
      "        0.1434, 0.1436, 0.1438, 0.1441, 0.1445, 0.1448, 0.1458, 0.1460, 0.1468,\n",
      "        0.1471, 0.1471], device='cuda:0')\n",
      "\n",
      "0 after loss adapt\n",
      " 0.03140377998352051\n",
      "after\toutput\n",
      " tensor([0.1310, 0.1875, 0.1525, 0.1659, 0.1804, 0.1391, 0.1987, 0.2260, 0.2075,\n",
      "        0.1518, 0.1423, 0.1225, 0.2226, 0.1931, 0.2164, 0.1811, 0.1793, 0.1862,\n",
      "        0.1474, 0.1395], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.1472, 0.1476, 0.1478, 0.1479, 0.1482, 0.1483, 0.1486, 0.1488, 0.1493,\n",
      "        0.1493, 0.1495, 0.1497, 0.1498, 0.1501, 0.1514, 0.1520, 0.1528, 0.1538,\n",
      "        0.1544, 0.1548], device='cuda:0')\n",
      "\n",
      "100 before loss adapt\n",
      " 0.5574832558631897\n",
      "before\toutput\n",
      " tensor([0.4735, 0.2186, 0.2988, 0.2628, 0.2200, 0.2843, 0.2773, 0.3426, 0.4008,\n",
      "        0.3078, 0.3247, 0.2831, 0.3004, 0.3376, 0.1435, 0.2793, 0.3703, 0.2863,\n",
      "        0.2886, 0.1946], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.8511, 0.8511, 0.8515, 0.8515, 0.8516, 0.8517, 0.8519, 0.8520, 0.8522,\n",
      "        0.8522, 0.8523, 0.8523, 0.8524, 0.8526, 0.8528, 0.8529, 0.8530, 0.8531,\n",
      "        0.8532, 0.8532], device='cuda:0')\n",
      "\n",
      "100 after loss adapt\n",
      " 0.2263675034046173\n",
      "after\toutput\n",
      " tensor([0.6699, 0.8193, 0.4023, 0.4602, 0.5971, 0.5776, 0.6159, 0.8019, 0.7447,\n",
      "        0.7848, 0.7345, 0.5429, 0.5732, 0.7545, 0.5830, 0.4441, 0.4959, 0.8244,\n",
      "        0.5980, 0.5382], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.8532, 0.8534, 0.8534, 0.8536, 0.8538, 0.8539, 0.8542, 0.8543, 0.8543,\n",
      "        0.8545, 0.8545, 0.8545, 0.8546, 0.8548, 0.8549, 0.8551, 0.8555, 0.8555,\n",
      "        0.8558, 0.8558], device='cuda:0')\n",
      "\n",
      "0 before loss adapt\n",
      " 0.07491298764944077\n",
      "before\toutput\n",
      " tensor([0.2260, 0.1670, 0.3045, 0.2260, 0.1488], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.1376, 0.1390, 0.1392, 0.1405, 0.1414], device='cuda:0')\n",
      "\n",
      "0 after loss adapt\n",
      " 0.010520505718886852\n",
      "after\toutput\n",
      " tensor([0.1496, 0.1485, 0.1455, 0.1264, 0.1622], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.1417, 0.1419, 0.1421, 0.1422, 0.1434], device='cuda:0')\n",
      "\n",
      "100 before loss adapt\n",
      " 0.21766310930252075\n",
      "before\toutput\n",
      " tensor([0.1508, 0.1580, 0.2407, 0.1937, 0.2407], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.4142, 0.4143, 0.4145, 0.4145, 0.4147], device='cuda:0')\n",
      "\n",
      "100 after loss adapt\n",
      " 0.12511977553367615\n",
      "after\toutput\n",
      " tensor([0.2822, 0.2989, 0.2992, 0.3472, 0.2261], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.4153, 0.4154, 0.4159, 0.4159, 0.4166], device='cuda:0')\n",
      "\n",
      "200 before loss adapt\n",
      " 0.29506269097328186\n",
      "before\toutput\n",
      " tensor([0.2732, 0.2747, 0.2637, 0.2487, 0.2757], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.5618, 0.5623, 0.5624, 0.5624, 0.5625], device='cuda:0')\n",
      "\n",
      "200 after loss adapt\n",
      " 0.17320159077644348\n",
      "after\toutput\n",
      " tensor([0.4127, 0.4035, 0.2330, 0.4234, 0.4742], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.5625, 0.5625, 0.5625, 0.5625, 0.5627], device='cuda:0')\n",
      "\n",
      "300 before loss adapt\n",
      " 0.45683011412620544\n",
      "before\toutput\n",
      " tensor([0.3387, 0.1984, 0.2204, 0.2767, 0.2770], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.7188, 0.7189, 0.7191, 0.7192, 0.7192], device='cuda:0')\n",
      "\n",
      "300 after loss adapt\n",
      " 0.3522700369358063\n",
      "after\toutput\n",
      " tensor([0.2706, 0.4494, 0.2587, 0.5547, 0.3026], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.7193, 0.7194, 0.7194, 0.7196, 0.7197], device='cuda:0')\n",
      "\n",
      "400 before loss adapt\n",
      " 0.5421599745750427\n",
      "before\toutput\n",
      " tensor([0.4026, 0.2638, 0.3721, 0.3684, 0.1390], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.8511, 0.8511, 0.8515, 0.8515, 0.8516], device='cuda:0')\n",
      "\n",
      "400 after loss adapt\n",
      " 0.334666907787323\n",
      "after\toutput\n",
      " tensor([0.5224, 0.5280, 0.4362, 0.5510, 0.5491], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.8517, 0.8519, 0.8520, 0.8522, 0.8522], device='cuda:0')\n",
      "\n",
      "0 before loss adapt\n",
      " 0.0986444428563118\n",
      "before\toutput\n",
      " tensor([0.2558, 0.1908, 0.3206, 0.2558, 0.1680], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.1376, 0.1390, 0.1392, 0.1405, 0.1414], device='cuda:0')\n",
      "\n",
      "0 after loss adapt\n",
      " 0.0236405897885561\n",
      "after\toutput\n",
      " tensor([0.1428, 0.1671, 0.1983, 0.1492, 0.1718], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.1417, 0.1419, 0.1421, 0.1422, 0.1434], device='cuda:0')\n",
      "\n",
      "100 before loss adapt\n",
      " 0.20019160211086273\n",
      "before\toutput\n",
      " tensor([0.1547, 0.1985, 0.2157, 0.2443, 0.2580], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.4142, 0.4143, 0.4145, 0.4145, 0.4147], device='cuda:0')\n",
      "\n",
      "100 after loss adapt\n",
      " 0.12469524890184402\n",
      "after\toutput\n",
      " tensor([0.2716, 0.3146, 0.3155, 0.2993, 0.2547], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.4153, 0.4154, 0.4159, 0.4159, 0.4166], device='cuda:0')\n",
      "\n",
      "200 before loss adapt\n",
      " 0.2583058178424835\n",
      "before\toutput\n",
      " tensor([0.3108, 0.2589, 0.2881, 0.3226, 0.3395], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.5618, 0.5623, 0.5624, 0.5624, 0.5625], device='cuda:0')\n",
      "\n",
      "200 after loss adapt\n",
      " 0.19321581721305847\n",
      "after\toutput\n",
      " tensor([0.3336, 0.3933, 0.2252, 0.4377, 0.4569], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.5625, 0.5625, 0.5625, 0.5625, 0.5627], device='cuda:0')\n",
      "\n",
      "300 before loss adapt\n",
      " 0.4353349208831787\n",
      "before\toutput\n",
      " tensor([0.3524, 0.2278, 0.2104, 0.2999, 0.3282], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.7188, 0.7189, 0.7191, 0.7192, 0.7192], device='cuda:0')\n",
      "\n",
      "300 after loss adapt\n",
      " 0.357314795255661\n",
      "after\toutput\n",
      " tensor([0.2539, 0.4172, 0.2655, 0.5268, 0.3475], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.7193, 0.7194, 0.7194, 0.7196, 0.7197], device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 before loss adapt\n",
      " 0.5162850022315979\n",
      "before\toutput\n",
      " tensor([0.3796, 0.3653, 0.3567, 0.2916, 0.2821], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.8511, 0.8511, 0.8515, 0.8515, 0.8516], device='cuda:0')\n",
      "\n",
      "400 after loss adapt\n",
      " 0.3531758785247803\n",
      "after\toutput\n",
      " tensor([0.4474, 0.5001, 0.4593, 0.5216, 0.5658], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.8517, 0.8519, 0.8520, 0.8522, 0.8522], device='cuda:0')\n",
      "\n",
      "0 before loss adapt\n",
      " 0.25266873836517334\n",
      "before\toutput\n",
      " tensor([0.4213, 0.3290, 0.4668, 0.4213, 0.3227], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.1376, 0.1390, 0.1392, 0.1405, 0.1414], device='cuda:0')\n",
      "\n",
      "0 after loss adapt\n",
      " 0.12059785425662994\n",
      "after\toutput\n",
      " tensor([0.2096, 0.3147, 0.2708, 0.1802, 0.3389], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.1417, 0.1419, 0.1421, 0.1422, 0.1434], device='cuda:0')\n",
      "\n",
      "100 before loss adapt\n",
      " 0.12891358137130737\n",
      "before\toutput\n",
      " tensor([0.2969, 0.2658, 0.2898, 0.2978, 0.2773], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.4142, 0.4143, 0.4145, 0.4145, 0.4147], device='cuda:0')\n",
      "\n",
      "100 after loss adapt\n",
      " 0.04677708074450493\n",
      "after\toutput\n",
      " tensor([0.4765, 0.4484, 0.4168, 0.5073, 0.3676], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.4153, 0.4154, 0.4159, 0.4159, 0.4166], device='cuda:0')\n",
      "\n",
      "200 before loss adapt\n",
      " 0.19704098999500275\n",
      "before\toutput\n",
      " tensor([0.4112, 0.3764, 0.3661, 0.3778, 0.2946], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.5618, 0.5623, 0.5624, 0.5624, 0.5625], device='cuda:0')\n",
      "\n",
      "200 after loss adapt\n",
      " 0.09663739055395126\n",
      "after\toutput\n",
      " tensor([0.4874, 0.5251, 0.2712, 0.5512, 0.4947], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.5625, 0.5625, 0.5625, 0.5625, 0.5627], device='cuda:0')\n",
      "\n",
      "300 before loss adapt\n",
      " 0.3820801377296448\n",
      "before\toutput\n",
      " tensor([0.3170, 0.3507, 0.2731, 0.3281, 0.4160], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.7188, 0.7189, 0.7191, 0.7192, 0.7192], device='cuda:0')\n",
      "\n",
      "300 after loss adapt\n",
      " 0.2982569634914398\n",
      "after\toutput\n",
      " tensor([0.4637, 0.4017, 0.3657, 0.4853, 0.3897], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.7193, 0.7194, 0.7194, 0.7196, 0.7197], device='cuda:0')\n",
      "\n",
      "400 before loss adapt\n",
      " 0.4639722406864166\n",
      "before\toutput\n",
      " tensor([0.3301, 0.4461, 0.4362, 0.4128, 0.3116], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.8511, 0.8511, 0.8515, 0.8515, 0.8516], device='cuda:0')\n",
      "\n",
      "400 after loss adapt\n",
      " 0.3620539903640747\n",
      "after\toutput\n",
      " tensor([0.4764, 0.4798, 0.5006, 0.4893, 0.5036], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.8517, 0.8519, 0.8520, 0.8522, 0.8522], device='cuda:0')\n",
      "\n",
      "0 before loss adapt\n",
      " 0.21029166877269745\n",
      "before\toutput\n",
      " tensor([0.3924, 0.2546, 0.4759, 0.3924, 0.2783, 0.2866, 0.3522, 0.3525, 0.3067,\n",
      "        0.4201], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.1376, 0.1390, 0.1392, 0.1405, 0.1414, 0.1417, 0.1419, 0.1421, 0.1422,\n",
      "        0.1434], device='cuda:0')\n",
      "\n",
      "0 after loss adapt\n",
      " 0.08705882728099823\n",
      "after\toutput\n",
      " tensor([0.2619, 0.1246, 0.1840, 0.2349, 0.2916, 0.1334, 0.1311, 0.3154, 0.3050,\n",
      "        0.2483], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.1436, 0.1438, 0.1441, 0.1445, 0.1448, 0.1458, 0.1460, 0.1468, 0.1471,\n",
      "        0.1471], device='cuda:0')\n",
      "\n",
      "100 before loss adapt\n",
      " 0.14410647749900818\n",
      "before\toutput\n",
      " tensor([0.4379, 0.4371, 0.4367, 0.5200, 0.2932, 0.4128, 0.4478, 0.1927, 0.5238,\n",
      "        0.4811], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.5618, 0.5623, 0.5624, 0.5624, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625,\n",
      "        0.5627], device='cuda:0')\n",
      "\n",
      "100 after loss adapt\n",
      " 0.18644022941589355\n",
      "after\toutput\n",
      " tensor([0.8634, 0.4141, 0.4549, 0.6875, 0.6396, 0.4231, 0.7764, 0.9020, 0.8688,\n",
      "        0.6710], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.5627, 0.5627, 0.5628, 0.5628, 0.5630, 0.5630, 0.5632, 0.5632, 0.5634,\n",
      "        0.5638], device='cuda:0')\n",
      "\n",
      "200 before loss adapt\n",
      " 0.4579799473285675\n",
      "before\toutput\n",
      " tensor([0.3762, 0.3942, 0.4558, 0.3704, 0.3704, 0.4619, 0.3130, 0.3757, 0.3096,\n",
      "        0.5098], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.8511, 0.8511, 0.8515, 0.8515, 0.8516, 0.8517, 0.8519, 0.8520, 0.8522,\n",
      "        0.8522], device='cuda:0')\n",
      "\n",
      "200 after loss adapt\n",
      " 0.2894682288169861\n",
      "after\toutput\n",
      " tensor([0.7164, 0.4770, 0.7334, 0.5621, 0.4171, 0.5757, 0.7270, 0.5328, 0.3738,\n",
      "        0.5178], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.8523, 0.8523, 0.8524, 0.8526, 0.8528, 0.8529, 0.8530, 0.8531, 0.8532,\n",
      "        0.8532], device='cuda:0')\n",
      "\n",
      "0 before loss adapt\n",
      " 0.2251054346561432\n",
      "before\toutput\n",
      " tensor([0.3911, 0.2804, 0.4273, 0.3911, 0.2850, 0.4676, 0.4285, 0.3053, 0.2678,\n",
      "        0.4159], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.1376, 0.1390, 0.1392, 0.1405, 0.1414, 0.1417, 0.1419, 0.1421, 0.1422,\n",
      "        0.1434], device='cuda:0')\n",
      "\n",
      "0 after loss adapt\n",
      " 0.13366204500198364\n",
      "after\toutput\n",
      " tensor([0.2675, 0.1772, 0.2989, 0.2485, 0.3055, 0.2165, 0.1884, 0.4192, 0.3188,\n",
      "        0.3494], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.1436, 0.1438, 0.1441, 0.1445, 0.1448, 0.1458, 0.1460, 0.1468, 0.1471,\n",
      "        0.1471], device='cuda:0')\n",
      "\n",
      "100 before loss adapt\n",
      " 0.11579913645982742\n",
      "before\toutput\n",
      " tensor([0.5925, 0.5690, 0.4936, 0.4484, 0.4096, 0.3976, 0.5795, 0.1980, 0.3925,\n",
      "        0.4930], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.5618, 0.5623, 0.5624, 0.5624, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625,\n",
      "        0.5627], device='cuda:0')\n",
      "\n",
      "100 after loss adapt\n",
      " 0.06219762563705444\n",
      "after\toutput\n",
      " tensor([0.6182, 0.4329, 0.5386, 0.5743, 0.4627, 0.7274, 0.5917, 0.5672, 0.6291,\n",
      "        0.5256], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.5627, 0.5627, 0.5628, 0.5628, 0.5630, 0.5630, 0.5632, 0.5632, 0.5634,\n",
      "        0.5638], device='cuda:0')\n",
      "\n",
      "200 before loss adapt\n",
      " 0.402912974357605\n",
      "before\toutput\n",
      " tensor([0.4236, 0.5263, 0.4551, 0.3519, 0.3642, 0.4395, 0.3517, 0.5716, 0.4545,\n",
      "        0.5492], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.8511, 0.8511, 0.8515, 0.8515, 0.8516, 0.8517, 0.8519, 0.8520, 0.8522,\n",
      "        0.8522], device='cuda:0')\n",
      "\n",
      "200 after loss adapt\n",
      " 0.20174401998519897\n",
      "after\toutput\n",
      " tensor([0.6782, 0.5712, 0.6907, 0.6410, 0.5337, 0.8270, 0.8033, 0.9403, 0.4168,\n",
      "        0.5832], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.8523, 0.8523, 0.8524, 0.8526, 0.8528, 0.8529, 0.8530, 0.8531, 0.8532,\n",
      "        0.8532], device='cuda:0')\n",
      "\n",
      "0 before loss adapt\n",
      " 0.06938385963439941\n",
      "before\toutput\n",
      " tensor([0.2553, 0.1043, 0.3324, 0.2553, 0.1573, 0.1296, 0.1515, 0.1731, 0.1240,\n",
      "        0.2904], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.1376, 0.1390, 0.1392, 0.1405, 0.1414, 0.1417, 0.1419, 0.1421, 0.1422,\n",
      "        0.1434], device='cuda:0')\n",
      "\n",
      "0 after loss adapt\n",
      " 0.05017649009823799\n",
      "after\toutput\n",
      " tensor([0.1041, 0.0703, 0.0805, 0.0948, 0.1200, 0.0890, 0.0851, 0.0837, 0.1455,\n",
      "        0.0799], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.1436, 0.1438, 0.1441, 0.1445, 0.1448, 0.1458, 0.1460, 0.1468, 0.1471,\n",
      "        0.1471], device='cuda:0')\n",
      "\n",
      "100 before loss adapt\n",
      " 0.30953332781791687\n",
      "before\toutput\n",
      " tensor([0.2258, 0.1492, 0.1672, 0.1270, 0.2912, 0.3803, 0.2579, 0.1056, 0.2997,\n",
      "        0.5248], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.5618, 0.5623, 0.5624, 0.5624, 0.5625, 0.5625, 0.5625, 0.5625, 0.5625,\n",
      "        0.5627], device='cuda:0')\n",
      "\n",
      "100 after loss adapt\n",
      " 0.11256333440542221\n",
      "after\toutput\n",
      " tensor([0.5536, 0.4797, 0.4117, 0.3522, 0.4062, 0.5705, 0.7810, 0.4967, 0.5654,\n",
      "        0.3435], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.5627, 0.5627, 0.5628, 0.5628, 0.5630, 0.5630, 0.5632, 0.5632, 0.5634,\n",
      "        0.5638], device='cuda:0')\n",
      "\n",
      "200 before loss adapt\n",
      " 0.4218306243419647\n",
      "before\toutput\n",
      " tensor([0.5699, 0.3456, 0.4221, 0.4899, 0.2254, 0.4162, 0.4629, 0.3953, 0.4582,\n",
      "        0.5129], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "before\tlabel\n",
      " tensor([0.8511, 0.8511, 0.8515, 0.8515, 0.8516, 0.8517, 0.8519, 0.8520, 0.8522,\n",
      "        0.8522], device='cuda:0')\n",
      "\n",
      "200 after loss adapt\n",
      " 0.19667887687683105\n",
      "after\toutput\n",
      " tensor([0.8544, 0.8002, 0.8480, 0.5900, 0.1877, 0.7510, 0.9009, 0.7358, 0.4687,\n",
      "        0.5237], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "after\tlabel\n",
      " tensor([0.8523, 0.8523, 0.8524, 0.8526, 0.8528, 0.8529, 0.8530, 0.8531, 0.8532,\n",
      "        0.8532], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tables=dict()\n",
    "for path in paths:\n",
    "    # 각 way or shot option 마다 ! \n",
    "    with open(path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "        device = torch.device('cuda')\n",
    "        benchmark = get_benchmark_by_name(config['dataset'],\n",
    "                                          config['num_ways'],\n",
    "                                          config['num_shots'],\n",
    "                                          config['num_shots_test'],\n",
    "                                          hidden_size=config['hidden_size'])\n",
    "        metalearner = ModelAgnosticMetaLearning(benchmark.model,\n",
    "                    first_order=config['first_order'],\n",
    "                    num_adaptation_steps=config['num_steps'],\n",
    "                    step_size=config['step_size'],\n",
    "                    loss_function=benchmark.loss_function,\n",
    "                    device=device)\n",
    "        \n",
    "        \n",
    "        way_size=int(config['num_ways'])\n",
    "        batch_size=way_size*2\n",
    "        dataset_loader = DataLoader(conv2d_dataset,\n",
    "                                                 batch_size=batch_size, shuffle=False,\n",
    "                                                 num_workers=1)\n",
    "        loss_before=[]\n",
    "        loss_after=[]\n",
    "        for idx,(data,label) in enumerate(dataset_loader):\n",
    "            model=metalearner.model\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "            data=data.to(device)\n",
    "            label=label.to(device)\n",
    "            if data.shape[0]!=batch_size:\n",
    "                break\n",
    "            with open(config['model_path'], 'rb') as f:\n",
    "                model.load_state_dict(torch.load(f, map_location=device))\n",
    "            output=model(data[:way_size])\n",
    "            loss=torch.nn.functional.l1_loss(output,label[:way_size])\n",
    "            if idx %100==0:\n",
    "                print(idx,'before loss adapt\\n',float(loss))\n",
    "                print('before\\toutput\\n',output.squeeze())\n",
    "                print('before\\tlabel\\n',label[:way_size].squeeze())\n",
    "                print()\n",
    "            loss_before.append(float(loss))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            output=model(data[way_size:])\n",
    "            loss=torch.nn.functional.l1_loss(output,label[way_size:])\n",
    "            if idx %100==0:\n",
    "                print(idx,'after loss adapt\\n',float(loss))\n",
    "                print('after\\toutput\\n',output.squeeze())\n",
    "                print('after\\tlabel\\n',label[way_size:].squeeze())\n",
    "                print()\n",
    "            loss_after.append(float(loss))\n",
    "            \n",
    "            \n",
    "        tables[f\"num_ways_{config['num_ways']}_num_shots_{config['num_shots']}\"]={'before':np.mean(loss_before),\n",
    "                                                              'after':np.mean(loss_after)}\n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(tables)\n",
    "df.to_csv('graph_flops_order_MAE.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MetaMLPModel(\n",
       "  (features): MetaSequential(\n",
       "    (layer1): MetaSequential(\n",
       "      (linear): MetaLinear(in_features=128, out_features=128, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (layer2): MetaSequential(\n",
       "      (linear): MetaLinear(in_features=128, out_features=128, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (layer3): MetaSequential(\n",
       "      (linear): MetaLinear(in_features=128, out_features=64, bias=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (classifier): MetaLinear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
